{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aN_d582T3ci3","outputId":"b783b6aa-fef9-49e0-c7bf-89851c1344c3","executionInfo":{"status":"ok","timestamp":1717397805712,"user_tz":420,"elapsed":23917,"user":{"displayName":"Brian Li","userId":"08121127222627393431"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZazYfOF-3l5C","outputId":"248d7af8-a168-4df9-f779-53471f8d4fc1","executionInfo":{"status":"ok","timestamp":1717397841374,"user_tz":420,"elapsed":248,"user":{"displayName":"Brian Li","userId":"08121127222627393431"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xtvc9aKb6DBj","outputId":"d0087b33-2c27-4971-af1a-5b66317500ce","executionInfo":{"status":"ok","timestamp":1717397852054,"user_tz":420,"elapsed":415,"user":{"displayName":"Brian Li","userId":"08121127222627393431"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1zcb8WXmpzPR8LBuK3Sg-LhTD6MtlZHvp/ECS174Project\n"]}],"source":["%cd /content/drive/Shareddrives/ECS174/ECS174Project\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMBtvUnm6K1t","outputId":"d518f0fb-6f51-4c1d-d627-d288baeac1fe","executionInfo":{"status":"ok","timestamp":1717397855579,"user_tz":420,"elapsed":752,"user":{"displayName":"Brian Li","userId":"08121127222627393431"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34m'Car Counting.v1i.darknet (1)'\u001b[0m/   \u001b[01;34mimages\u001b[0m/                               with_bus_and_truck.ipynb\n","'Car Counting.v1i.darknet.zip'    latest.ipynb                          with_CV.ipynb\n"," ECS174GroupProject.ipynb         vehicle_color_haze_free_model.h5      \u001b[01;34myolo\u001b[0m/\n"," \u001b[01;34mECS174report\u001b[0m/                   \u001b[01;34m'Vehicle Detection.v2-vvvv.darknet'\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ca5Wh5224cb3"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import os\n","\n","names_path = \"./yolo/coco.names\"\n","\n","def calculate_overall_accuracy(tp, fp, fn):\n","    accuracy = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n","    return accuracy\n","\n","def calculate_metrics(tp, fp, fn):\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","    return precision, recall, f1_score\n","\n","def predict_cars_buses_trucks(net, yolo_version, show_details):\n","    layer_names = net.getLayerNames()\n","\n","    # Handle different formats of getUnconnectedOutLayers output\n","    unconnected_out_layers = net.getUnconnectedOutLayers()\n","    if isinstance(unconnected_out_layers[0], list) or isinstance(unconnected_out_layers[0], np.ndarray):\n","        output_layers = [layer_names[i[0] - 1] for i in unconnected_out_layers]\n","    else:\n","        output_layers = [layer_names[i - 1] for i in unconnected_out_layers]\n","\n","    # Load COCO names\n","    with open(names_path, \"r\") as f:\n","        classes = [line.strip() for line in f.readlines()]\n","\n","    # Function to get image paths from a folder\n","    def get_image_paths(folder):\n","        image_paths = []\n","        for root, dirs, files in os.walk(folder):\n","            for file in files:\n","                if file.endswith(\".jpg\"):\n","                    image_paths.append(os.path.join(root, file))\n","                    # break\n","        return image_paths\n","\n","    # test_folder = \"./testing\"\n","    # test_folder = \"./Vehicle Detection.v2-vvvv.darknet/test\"\n","    test_folder = \"./Vehicle Detection.v2-vvvv.darknet/combined\"\n","\n","\n","    # Get all image paths from the test folder\n","    image_paths = get_image_paths(test_folder)\n","\n","    correct = {\"cars\": 0, \"buses\": 0, \"trucks\": 0}\n","\n","    # Overall metrics\n","    overall_tp_cars, overall_tp_buses, overall_tp_trucks = 0, 0, 0\n","    overall_fp_cars, overall_fp_buses, overall_fp_trucks = 0, 0, 0\n","    overall_fn_cars, overall_fn_buses, overall_fn_trucks = 0, 0, 0\n","\n","    # Process each image\n","    for image_path in image_paths:\n","        ground_truth = {\"num_cars\": 0, \"num_buses\": 0, \"num_trucks\": 0}\n","\n","        # Get ground truth from the image path\n","        with open(image_path.replace(\".jpg\", \".txt\"), \"r\") as f:\n","            labels = [line.split() for line in f.readlines()]\n","            for label in labels:\n","                match label[0]:\n","                    # Ignore motorcycles\n","                    case \"0\": continue\n","                    case \"1\": ground_truth[\"num_cars\"] += 1\n","                    case \"2\": ground_truth[\"num_cars\"] += 1\n","                    case \"3\": ground_truth[\"num_trucks\"] += 1\n","                    case \"4\": ground_truth[\"num_cars\"] += 1\n","                    case \"5\": ground_truth[\"num_buses\"] += 1\n","                    case \"6\": ground_truth[\"num_cars\"] += 1\n","                    case \"7\": ground_truth[\"num_cars\"] += 1\n","\n","        image = cv2.imread(image_path)\n","\n","        # Check if image is loaded\n","        if image is None:\n","            print(f\"Error: Unable to load image at {image_path}\")\n","            continue\n","\n","        height, width, channels = image.shape\n","\n","        # Detecting objects\n","        blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n","        net.setInput(blob)\n","        outs = net.forward(output_layers)\n","\n","        # Initialize parameters\n","        class_ids = []\n","        confidences = []\n","        boxes = []\n","\n","        # Extract information from the detections\n","        for out in outs:\n","            for detection in out:\n","                scores = detection[5:]\n","                class_id = np.argmax(scores)\n","                confidence = scores[class_id]\n","                if confidence > 0.5:\n","                    # Object detected\n","                    center_x = int(detection[0] * width)\n","                    center_y = int(detection[1] * height)\n","                    w = int(detection[2] * width)\n","                    h = int(detection[3] * height)\n","\n","                    # Rectangle coordinates\n","                    x = int(center_x - w / 2)\n","                    y = int(center_y - h / 2)\n","\n","                    boxes.append([x, y, w, h])\n","                    confidences.append(float(confidence))\n","                    class_ids.append(class_id)\n","\n","        # Non-max suppression\n","        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n","\n","        # Count cars, buses, and trucks\n","        car_count = 0\n","        bus_count = 0\n","        truck_count = 0\n","        for i in range(len(boxes)):\n","            if i in indexes:\n","                x, y, w, h = boxes[i]\n","                label = str(classes[class_ids[i]])\n","                if label == \"car\":\n","                    car_count += 1\n","                    if show_details:\n","                        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","                        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","                elif label == \"bus\":\n","                    bus_count += 1\n","                    if show_details:\n","                        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n","                        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n","                elif label == \"truck\":\n","                    truck_count += 1\n","                    if show_details:\n","                        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n","                        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n","\n","        if show_details:\n","            print(f\"Ground truth:\\t{ground_truth['num_cars']} cars,\\t{ground_truth['num_buses']} buses,\\t{ground_truth['num_trucks']} trucks\")\n","            print(f\"Predicted: \\t{car_count} cars,\\t{bus_count} buses,\\t{truck_count} trucks\")\n","\n","            # Convert the image from BGR to RGB\n","            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            plt.figure(figsize=(10, 10))\n","            plt.imshow(image_rgb)\n","            plt.axis('off')\n","            plt.title(f\"YOLOv{yolo_version} Detections\", fontsize=20)\n","            plt.show()\n","\n","        # Calculate performance metrics\n","        tp_cars, tp_buses, tp_trucks = 0, 0, 0\n","        fp_cars, fp_buses, fp_trucks = 0, 0, 0\n","        fn_cars, fn_buses, fn_trucks = 0, 0, 0\n","\n","        for label in labels:\n","            class_id = int(label[0])\n","            x = float(label[1]) * width\n","            y = float(label[2]) * height\n","            w = float(label[3]) * width\n","            h = float(label[4]) * height\n","\n","            # Cars\n","            if class_id in [1, 2, 4, 6, 7]:\n","                if car_count > 0:\n","                    tp_cars += 1\n","                    car_count -= 1\n","                else:\n","                    fn_cars += 1\n","            # Bus\n","            elif class_id == 5:\n","                if bus_count > 0:\n","                    tp_buses += 1\n","                    bus_count -= 1\n","                else:\n","                    fn_buses += 1\n","            # Truck\n","            elif class_id == 3:\n","                if truck_count > 0:\n","                    tp_trucks += 1\n","                    truck_count -= 1\n","                else:\n","                    fn_trucks += 1\n","\n","        fp_cars = car_count\n","        fp_buses = bus_count\n","        fp_trucks = truck_count\n","\n","        # Update overall metrics\n","        overall_tp_cars += tp_cars\n","        overall_tp_buses += tp_buses\n","        overall_tp_trucks += tp_trucks\n","\n","        overall_fp_cars += fp_cars\n","        overall_fp_buses += fp_buses\n","        overall_fp_trucks += fp_trucks\n","\n","        overall_fn_cars += fn_cars\n","        overall_fn_buses += fn_buses\n","        overall_fn_trucks += fn_trucks\n","\n","        if show_details:\n","            print(f\"True Positives - Cars: {tp_cars}, Buses: {tp_buses}, Trucks: {tp_trucks}\")\n","            print(f\"False Positives - Cars: {fp_cars}, Buses: {fp_buses}, Trucks: {fp_trucks}\")\n","            print(f\"False Negatives - Cars: {fn_cars}, Buses: {fn_buses}, Trucks: {fn_trucks}\")\n","\n","    # Calculate the overall accuracy\n","    overall_tp = overall_tp_cars + overall_tp_buses + overall_tp_trucks\n","    overall_fp = overall_fp_cars + overall_fp_buses + overall_fp_trucks\n","    overall_fn = overall_fn_cars + overall_fn_buses + overall_fn_trucks\n","    overall_accuracy = calculate_overall_accuracy(overall_tp, overall_fp, overall_fn)\n","\n","    # Calculate overall metrics\n","    car_metrics = calculate_metrics(overall_tp_cars, overall_fp_cars, overall_fn_cars)\n","    bus_metrics = calculate_metrics(overall_tp_buses, overall_fp_buses, overall_fn_buses)\n","    truck_metrics = calculate_metrics(overall_tp_trucks, overall_fp_trucks, overall_fn_trucks)\n","\n","    print(f\"Overall Performance of YOLOv{yolo_version} on the test set:\")\n","    print(f\"Precision for Cars: {car_metrics[0]:.2f}, Recall for Cars: {car_metrics[1]:.2f}, F1 Score for Cars: {car_metrics[2]:.2f}\")\n","    print(f\"Precision for Buses: {bus_metrics[0]:.2f}, Recall for Buses: {bus_metrics[1]:.2f}, F1 Score for Buses: {bus_metrics[2]:.2f}\")\n","    print(f\"Precision for Trucks: {truck_metrics[0]:.2f}, Recall for Trucks: {truck_metrics[1]:.2f}, F1 Score for Trucks: {truck_metrics[2]:.2f}\")\n","\n","    print(f\"Overall Accuracy: {overall_accuracy:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9eQqMGNLYELF","outputId":"4ad300ef-9cfb-4cc7-d34f-50559708f4d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overall Performance of YOLOv2 on the test set:\n","Precision for Cars: 0.98, Recall for Cars: 0.16, F1 Score for Cars: 0.28\n","Precision for Buses: 0.20, Recall for Buses: 0.08, F1 Score for Buses: 0.12\n","Precision for Trucks: 0.86, Recall for Trucks: 0.03, F1 Score for Trucks: 0.06\n","Overall Accuracy: 0.14\n","\n","Other accuracy calculation:\n","Percentage accuracy for cars: 0.00%\n","Percentage accuracy for buses: 0.00%\n","Percentage accuracy for trucks: 0.00%\n"]}],"source":["show_details = False\n","\n","\"\"\"\n","explain why accuracy with TN calculation cant be used\n","accuracy = (TP + TN) / (TP + TN + FP + FN)\n","\n","accuracy is calculated using the class_id and the number of cars, buses, and trucks detected\n","\n","TODO: run again (will show the overall accuracy)\n","\"\"\"\n","\n","# Load YOLOv2\n","weights_path = \"./yolo/yolov2.weights\"\n","config_path = \"./yolo/yolov2.cfg\"\n","\n","net = cv2.dnn.readNet(weights_path, config_path)\n","\n","predict_cars_buses_trucks(net, yolo_version=2, show_details=show_details)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArAwCjiY4cb4","outputId":"ffa33c2c-7acc-432f-a0c9-a473a0071419"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overall Performance of YOLOv3 on the test set:\n","Precision for Cars: 0.46, Recall for Cars: 0.96, F1 Score for Cars: 0.62\n","Precision for Buses: 0.14, Recall for Buses: 0.51, F1 Score for Buses: 0.23\n","Precision for Trucks: 0.43, Recall for Trucks: 0.84, F1 Score for Trucks: 0.57\n","Overall Accuracy: 0.44\n","\n","Other accuracy calculation:\n","Percentage accuracy for cars: 0.00%\n","Percentage accuracy for buses: 0.00%\n","Percentage accuracy for trucks: 0.00%\n"]}],"source":["# Load YOLOv3\n","weights_path = \"./yolo/yolov3.weights\"\n","config_path = \"./yolo/yolov3.cfg\"\n","\n","net = cv2.dnn.readNet(weights_path, config_path)\n","\n","predict_cars_buses_trucks(net, yolo_version=3, show_details=show_details)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jpk9SUd4cb5","outputId":"1c7d4464-b6e2-4120-ff9c-0d78d8dbb9f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overall Performance of YOLOv4 on the test set:\n","Precision for Cars: 0.62, Recall for Cars: 0.90, F1 Score for Cars: 0.74\n","Precision for Buses: 0.21, Recall for Buses: 0.61, F1 Score for Buses: 0.31\n","Precision for Trucks: 0.36, Recall for Trucks: 0.91, F1 Score for Trucks: 0.52\n","Overall Accuracy: 0.52\n","\n","Other accuracy calculation:\n","Percentage accuracy for cars: 0.00%\n","Percentage accuracy for buses: 0.00%\n","Percentage accuracy for trucks: 0.00%\n"]}],"source":["# Load YOLOv4\n","weights_path = \"./yolo/yolov4.weights\"\n","config_path = \"./yolo/yolov4.cfg\"\n","\n","net = cv2.dnn.readNet(weights_path, config_path)\n","\n","predict_cars_buses_trucks(net, yolo_version=4, show_details=show_details)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8Fm7j_64cb6"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}